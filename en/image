#pragma once

#include "support/Common.h"

// 获取rgb图片所需内存大小    BitCount=32
// int width: 宽
// int height: 高
// int: 图片大小
int GetRGBBufferLength(int width, int height);

// 入参bmp只有数据，不包含bmp头   
// int width: bmp图宽
// int height: bmp图高
// char * bmp_buf: bmp数据指针   分配的内存需调用者自行回收
// int bmp_len: bmp数据长度
// DataStruct * data_struct: yuv结构体
// bool: 转换结果
bool ConvertBitmapToYUV420(int width, int height, char* bmp_buf, int bmp_len, DataStruct* data_struct);

// int width: 
// int height: 
// char * yuv_buif:   分配的内存需调用者自行回收
// int yuv_len: 
// DataStruct * data_struct: 
// bool: 
bool ConvertYUV420ToBitmap(int width, int height, char* yuv_buif, int yuv_len, DataStruct* data_struct);

bool SaveBitmap(DataStruct* ptr_data);

// 转化为bitmap图像带头的字节流
// DataStruct * ptr_data: 
// int & length: 输出字节长度
// char * buffer: 输出字节流  函数内分配   调用者回收
// void: 
void SaveBitmapToBuffer(DataStruct* ptr_data, BitmapFileStruct* ptr_stru);

------------------------------------------


#include "ImageFunctions.h"

#include <QDebug>

#include <Windows.h>
#include <WinUser.h>

#ifdef __cplusplus 
extern "C" {
#endif

#include <libavcodec/avcodec.h>
#include <libavutil/opt.h>
#include <libavutil/imgutils.h>
#include <libswscale/swscale.h> 

	static bool C_ConvertBitmapToYUV420(int width, int height, char* bmp_buf, int bmp_len, DataStruct* data_struct)
	{
		// 带P格式则分量存在不同数组中   如YUV分别在0 1 2中
		// SWS_BICUBIC 效果好 速度慢  SWS_FAST_BILINEAR平衡  SWS_POINT效果差  速度快

			data_struct->buffer_length_ = width * height * 3 / 2;
			data_struct->buffer_ = new char[data_struct->buffer_length_];
			data_struct->width_ = width;
			data_struct->height_ = height;

		AVFrame* pFrame = new AVFrame[1];
		AVFrame *pFrameRGB = new AVFrame[1];

		avpicture_fill((AVPicture *)pFrameRGB, (uint8_t *)bmp_buf, AV_PIX_FMT_RGB32, width, height);

		avpicture_fill((AVPicture *)pFrame, (uint8_t *)data_struct->buffer_, AV_PIX_FMT_YUV420P, width, height);

		SwsContext *img_convert_ctx = sws_getContext(width, height, AV_PIX_FMT_RGB32, width, height, AV_PIX_FMT_YUV420P, SWS_POINT, NULL, NULL, NULL);

		sws_scale(img_convert_ctx,
			(uint8_t const * const *)pFrameRGB->data,
			pFrameRGB->linesize, 0, height, pFrame->data,
			pFrame->linesize);

		sws_freeContext(img_convert_ctx);

		delete[] pFrame;
		delete[] pFrameRGB;

		return true;
	}

	static bool C_ConvertYUV420ToBitmap(int width, int height, char* yuv_buif, int yuv_len, DataStruct* data_struct)
	{
		// 带P格式则分量存在不同数组中   如YUV分别在0 1 2中
		// SWS_BICUBIC 效果好 速度慢  SWS_FAST_BILINEAR平衡  SWS_POINT效果差  速度快

		data_struct->buffer_length_ = ((width * 32 + 31) / 32) * 4 * height;
		data_struct->buffer_ = new char[data_struct->buffer_length_];
		data_struct->width_ = width;
		data_struct->height_ = height;

		AVFrame *pFrameYUV = new AVFrame[1];
		AVFrame *pFrameRGB = new AVFrame[1];

		avpicture_fill((AVPicture *)pFrameRGB, (uint8_t *)data_struct->buffer_, AV_PIX_FMT_RGB32, width, height);

		avpicture_fill((AVPicture *)pFrameYUV, (uint8_t *)yuv_buif, AV_PIX_FMT_YUV420P, width, height);

		SwsContext *img_convert_ctx = sws_getContext(width, height, AV_PIX_FMT_YUV420P, width, height, AV_PIX_FMT_RGB32, SWS_POINT, NULL, NULL, NULL);

		int temp = sws_scale(img_convert_ctx,
			(uint8_t const * const *)pFrameYUV->data,
			pFrameYUV->linesize, 0, height, pFrameRGB->data,
			pFrameRGB->linesize);

		sws_freeContext(img_convert_ctx);

		delete[] pFrameYUV;
		delete[] pFrameRGB;

		return true;
	}

#ifdef __cplusplus 
}
#endif

bool ConvertBitmapToYUV420(int width, int height, char* bmp_buf, int bmp_len, DataStruct* data_struct)
{
	if (bmp_buf == NULL || bmp_len == 0)
	{
		return false;
	}

	return C_ConvertBitmapToYUV420(width, height, bmp_buf, bmp_len, data_struct);
}

bool ConvertYUV420ToBitmap(int width, int height, char* yuv_buif, int yuv_len, DataStruct* data_struct)
{
	if (yuv_buif == NULL || yuv_len == 0)
	{
		return false;
	}

	return C_ConvertYUV420ToBitmap(width, height, yuv_buif, yuv_len, data_struct);
}

bool SaveBitmap(DataStruct* ptr_data)
{
	// A file is created, this is where we will save the screen capture.
	HANDLE hFile = CreateFile(L"D:/captureqwsx.bmp",
		GENERIC_WRITE,
		0,
		NULL,
		CREATE_ALWAYS,
		FILE_ATTRIBUTE_NORMAL, NULL);

	// Add the size of the headers to the size of the bitmap to get the total file size
	DWORD dwSizeofDIB = ptr_data->buffer_length_ + sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);

	BITMAPFILEHEADER bmfHeader;
	//Offset to where the actual bitmap bits start.
	bmfHeader.bfOffBits = (DWORD)sizeof(BITMAPFILEHEADER) + (DWORD)sizeof(BITMAPINFOHEADER);

	//Size of the file
	bmfHeader.bfSize = dwSizeofDIB;

	//bfType must always be BM for Bitmaps
	bmfHeader.bfType = 0x4D42; //BM   

	BITMAPINFOHEADER bi;
	bi.biSize = sizeof(BITMAPINFOHEADER);
	bi.biWidth = ptr_data->width_;
	bi.biHeight = ptr_data->height_;
	bi.biPlanes = 1;
	bi.biBitCount = 32;
	bi.biCompression = BI_RGB;
	bi.biSizeImage = 0;
	bi.biXPelsPerMeter = 0;
	bi.biYPelsPerMeter = 0;
	bi.biClrUsed = 0;
	bi.biClrImportant = 0;

	DWORD dwBytesWritten = 0;
	WriteFile(hFile, (LPSTR)&bmfHeader, sizeof(BITMAPFILEHEADER), &dwBytesWritten, NULL);
	WriteFile(hFile, (LPSTR)&bi, sizeof(BITMAPINFOHEADER), &dwBytesWritten, NULL);
	WriteFile(hFile, (LPSTR)ptr_data->buffer_, ptr_data->buffer_length_, &dwBytesWritten, NULL);

	//Close the handle for the file that was created
	CloseHandle(hFile);

	return true;
}

void SaveBitmapToBuffer(DataStruct* ptr_data, BitmapFileStruct* ptr_stru)
{
	// Add the size of the headers to the size of the bitmap to get the total file size
	DWORD dwSizeofDIB = ptr_data->buffer_length_ + sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);

	BITMAPFILEHEADER bmfHeader;
	//Offset to where the actual bitmap bits start.
	bmfHeader.bfOffBits = (DWORD)sizeof(BITMAPFILEHEADER) + (DWORD)sizeof(BITMAPINFOHEADER);

	//Size of the file
	bmfHeader.bfSize = dwSizeofDIB;

	//bfType must always be BM for Bitmaps
	bmfHeader.bfType = 0x4D42; //BM   

	BITMAPINFOHEADER bi;
	bi.biSize = sizeof(BITMAPINFOHEADER);
	bi.biWidth = ptr_data->width_;
	bi.biHeight = ptr_data->height_;
	bi.biPlanes = 1;
	bi.biBitCount = 32;
	bi.biCompression = BI_RGB;
	bi.biSizeImage = 0;
	bi.biXPelsPerMeter = 0;
	bi.biYPelsPerMeter = 0;
	bi.biClrUsed = 0;
	bi.biClrImportant = 0;

	ptr_stru->length = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER) + ptr_data->buffer_length_;
	ptr_stru->buffer = new char[ptr_stru->length];

	memcpy(ptr_stru->buffer, (LPSTR)&bmfHeader, sizeof(BITMAPFILEHEADER));
	memcpy(ptr_stru->buffer, (LPSTR)&bi, sizeof(BITMAPINFOHEADER));
	memcpy(ptr_stru->buffer, (LPSTR)ptr_data->buffer_, ptr_data->buffer_length_);
}

int GetRGBBufferLength(int width, int height)
{
	// ((w * BitCount + 31) / 32) * 4 * h;   此处截图始终32   实际没啥用  24就有用了（后期改用24提升性能？）
	return  ((width * kCaptureBitCount + 31) / 32) * 4 * height;
}

//#ifdef __cplusplus 
//extern "C" {
//#endif
//
//#include <libavcodec/avcodec.h>
//#include <libavutil/opt.h>
//#include <libavutil/imgutils.h>
//#include <libswscale/swscale.h> 
//
//	void ConvertBitmapToH264(int width, int height, char* bmp_buf, int bmp_len, char* h264_buf, int &h264_len)
//	{
//		AVFrame *m_pRGBFrame = new AVFrame[1];  //RGB帧数据    
//		AVFrame *m_pYUVFrame = new AVFrame[1];;  //YUV帧数据  
//		AVCodecContext *c = NULL;
//		AVCodec *ptr_h264_coder = avcodec_find_encoder_by_name("libx264");
//		if (!ptr_h264_coder) {
//			qDebug() << "Codec not found";
//		}
//		uint8_t * yuv_buff;//  
//
//		c = avcodec_alloc_context3(ptr_h264_coder);
//		c->bit_rate = 3000000;// put sample parameters   
//		c->width = width;//   
//		c->height = height;//   
//		AVRational rate;
//		rate.num = 1;
//		rate.den = 25;
//		c->time_base = rate;//(AVRational){1,25};  
//		c->gop_size = 10; // emit one intra frame every ten frames   
//		c->max_b_frames = 1;
//		c->thread_count = 1;
//		c->pix_fmt = AV_PIX_FMT_YUV420P;
//
//		if (avcodec_open2(c, ptr_h264_coder, NULL) < 0) {
//			qDebug() << " avcodec_open2 failed";
//		}
//
//		int size = c->width * c->height;
//		yuv_buff = (uint8_t *)malloc((size * 3) / 2); // size for YUV 420   
//
//		uint8_t * rgb_buff = new uint8_t[bmp_len]; // buf for rgb
//
//		int outbuf_size = 900000;
//		uint8_t * outbuf = (uint8_t*)malloc(outbuf_size);
//		int u_size = 0;
//		FILE *f = NULL;
//		char * filename = "./myData.h264";
//		f = fopen(filename, "wb");
//		if (!f)
//		{
//			qDebug() << "open h264 file failed";
//		}
//
//		SwsContext * scxt = sws_getContext(c->width, c->height, AV_PIX_FMT_BGR24, c->width, c->height, AV_PIX_FMT_YUV420P, SWS_POINT, NULL, NULL, NULL);
//
//		AVPacket avpkt;
//		//for (int i = 0; i < 250; ++i)
//		for (int i = 0; i < 1; ++i)
//		{
//
//			//AVFrame *m_pYUVFrame = new AVFrame[1];  
//
//			int index = (i / 25) % 5;
//			memcpy(rgb_buff, bmp_buf, bmp_len);
//
//			avpicture_fill((AVPicture*)m_pRGBFrame, (uint8_t*)rgb_buff, AV_PIX_FMT_RGB24, width, height);
//
//			//将YUV buffer 填充YUV Frame  
//			avpicture_fill((AVPicture*)m_pYUVFrame, (uint8_t*)yuv_buff, AV_PIX_FMT_YUV420P, width, height);
//
//			// 翻转RGB图像  
//			m_pRGBFrame->data[0] += m_pRGBFrame->linesize[0] * (height - 1);
//			m_pRGBFrame->linesize[0] *= -1;
//			m_pRGBFrame->data[1] += m_pRGBFrame->linesize[1] * (height / 2 - 1);
//			m_pRGBFrame->linesize[1] *= -1;
//			m_pRGBFrame->data[2] += m_pRGBFrame->linesize[2] * (height / 2 - 1);
//			m_pRGBFrame->linesize[2] *= -1;
//
//
//			//将RGB转化为YUV  
//			sws_scale(scxt, m_pRGBFrame->data, m_pRGBFrame->linesize, 0, c->height, m_pYUVFrame->data, m_pYUVFrame->linesize);
//
//			static int got_packet_ptr = 0;
//			av_init_packet(&avpkt);
//			avpkt.data = outbuf;
//			avpkt.size = outbuf_size;
//			u_size = avcodec_encode_video2(c, &avpkt, m_pYUVFrame, &got_packet_ptr);
//			m_pYUVFrame->pts++;
//			if (u_size == 0)
//			{
//				fwrite(avpkt.data, 1, avpkt.size, f);
//			}
//		}
//
//		fclose(f);
//		delete[]m_pRGBFrame;
//		delete[]m_pYUVFrame;
//		delete[]rgb_buff;
//		free(outbuf);
//		avcodec_close(c);
//		av_free(c);
//	}
//
//#ifdef __cplusplus 
//}
//#endif


//static void encode(AVCodecContext *enc_ctx, AVFrame *frame, AVPacket *pkt,
//	FILE *outfile)
//{
//	int ret;
//	/* send the frame to the encoder */
//	if (frame)
//		qDebug() << "Send frame %3 PRId64" << frame->pts;
//	ret = avcodec_send_frame(enc_ctx, frame);
//	if (ret < 0) {
//		qDebug() << "Error sending a frame for encoding";
//		exit(1);
//	}
//	while (ret >= 0) {
//		ret = avcodec_receive_packet(enc_ctx, pkt);
//		if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
//			return;
//		else if (ret < 0) {
//			fprintf(stderr, "Error during encoding\n");
//			exit(1);
//		}
//		qDebug() << "Write packet" << pkt->pts << pkt->size;
//		fwrite(pkt->data, 1, pkt->size, outfile);
//		av_packet_unref(pkt);
//	}
//}


//static void ConvertBitmapToH264()
//{
//	const char *filename, *codec_name;
//	const AVCodec *codec;
//	AVCodecContext *c = NULL;
//	int i, ret, x, y;
//	FILE *f;
//	AVFrame *frame;
//	AVPacket *pkt;
//	uint8_t endcode[] = { 0, 0, 1, 0xb7 };
//
//	filename = "./what";
//	codec_name = "libx264";
//	/* find the mpeg1video encoder */
//	codec = avcodec_find_encoder_by_name(codec_name);
//	if (!codec) {
//		qDebug() << "Codec not found" << codec_name;
//	}
//	c = avcodec_alloc_context3(codec);
//	if (!c) {
//		qDebug() << "Could not allocate video codec context";
//	}
//	pkt = av_packet_alloc();
//	if (!pkt)
//		qDebug() << "alloc failed";
//	/* put sample parameters */
//	c->bit_rate = 400000;
//	/* resolution must be a multiple of two */
//	c->width = 352;
//	c->height = 288;
//	/* frames per second */
//	AVRational time_base;
//	time_base.num = 1;
//	time_base.den = 25;
//	c->time_base = time_base;
//	AVRational framerate;
//	framerate.num = 25;
//	framerate.den = 1;
//	c->framerate = framerate;
//	/* emit one intra frame every ten frames
//	* check frame pict_type before passing frame
//	* to encoder, if frame->pict_type is AV_PICTURE_TYPE_I
//	* then gop_size is ignored and the output of encoder
//	* will always be I frame irrespective to gop_size
//	*/
//	c->gop_size = 10;
//	c->max_b_frames = 1;
//	c->pix_fmt = AV_PIX_FMT_ARGB;  //AV_PIX_FMT_ARGB AV_PIX_FMT_YUV420P
//	if (codec->id == AV_CODEC_ID_H264)
//		av_opt_set(c->priv_data, "preset", "slow", 0);
//	/* open it */
//	ret = avcodec_open2(c, codec, NULL);
//	if (ret < 0) {
//		qDebug() << "Could not open codec: " << ret;
//		exit(1);
//	}
//	f = fopen(filename, "wb");
//	if (!f) {
//		fprintf(stderr, "Could not open %s\n", filename);
//	}
//	frame = av_frame_alloc();
//	if (!frame) {
//		fprintf(stderr, "Could not allocate video frame\n");
//	}
//	frame->format = c->pix_fmt;
//	frame->width = c->width;
//	frame->height = c->height;
//	ret = av_frame_get_buffer(frame, 32);
//	if (ret < 0) {
//		fprintf(stderr, "Could not allocate the video frame data\n");
//	}
//	/* encode 1 second of video */
//	for (i = 0; i < 25; i++) {
//		fflush(stdout);
//		/* make sure the frame data is writable */
//		ret = av_frame_make_writable(frame);
//		if (ret < 0)
//			qDebug() << "av_frame_make_writable failed";
//		/* prepare a dummy image */
//		/* Y */
//		for (y = 0; y < c->height; y++) {
//			for (x = 0; x < c->width; x++) {
//				frame->data[0][y * frame->linesize[0] + x] = x + y + i * 3;
//			}
//		}
//		/* Cb and Cr */
//		for (y = 0; y < c->height / 2; y++) {
//			for (x = 0; x < c->width / 2; x++) {
//				frame->data[1][y * frame->linesize[1] + x] = 128 + y + i * 2;
//				frame->data[2][y * frame->linesize[2] + x] = 64 + x + i * 5;
//			}
//		}
//		frame->pts = i;
//		/* encode the image */
//		encode(c, frame, pkt, f);
//	}
//	/* flush the encoder */
//	encode(c, NULL, pkt, f);
//	/* add sequence end code to have a real MPEG file */
//	fwrite(endcode, 1, sizeof(endcode), f);
//	fclose(f);
//	avcodec_free_context(&c);
//	av_frame_free(&frame);
//	av_packet_free(&pkt);
//}
