#pragma once

#include "support/Common.h"

// yuv转h264
// int channel: 
// DataStruct * ptr_data: 
// BufferNode * ptr_bs: h264数据指针   外部分配链表头  函数内新建链表节点   （可能多个）
// int: 0成功
int ConvertYUVToH264(int channel, DataStruct* ptr_data, BufferNode* ptr_bs);

int ConvertH264ToYUV(int channel, BufferNode* ptr_bs, DataStruct* ptr_data);

// rgb转h264
// int channel: 编码通道  
// DataStruct * ptr_rgb_data: in rgb数据
// BufferNode * ptr_h264: out 外部分配  只能一个   （据说一帧只出一个包  实际待验证  若多个得改）
// int: 0成功
int ConvertRGBToH264(int channel, DataStruct* ptr_rgb_data, BufferNode* ptr_h264);

// h264转rgb
// int channel: 编码通道  
// BufferNode * ptr_h264: in h264数据  只能一个   （据说一帧只出一个包  实际待验证  若多个得改）
// DataStruct * ptr_rgb_data: out rgb数据 外部分配内存
// int: 0成功
int ConvertH264ToRGB(int channel, BufferNode* ptr_h264, DataStruct* ptr_rgb_data);



#include "ImageFunctions.h"

#include <QProcess>
#include <QFile>
#include <QDebug>

#include <Windows.h>
#include <WinUser.h>

#ifdef __cplusplus 
extern "C" {
#endif

#include <libavcodec/avcodec.h>
#include <libavutil/opt.h>
#include <libavutil/imgutils.h>
#include <libswscale/swscale.h> 
#include <libavformat/avformat.h>
#include <libavutil/log.h>

	void FFMPEGPrintError(int code)
	{
		char* error_buf = new char[1000];
		av_strerror(code, error_buf, 1000);
		fprintf(stderr, error_buf);
		delete[] error_buf;
	}

	struct H264EncodeInfoStru
	{
		bool Init()
		{
			if (is_inited)
			{
				return true;
			}

			av_register_all();
			avformat_network_init();

			codec = avcodec_find_encoder(AV_CODEC_ID_H264);

			if (!codec)
			{
				return false;
			}

			c = avcodec_alloc_context3(codec);
			if (!c)
			{
				return false;
			}

			pkt = av_packet_alloc();
			if (!pkt)
			{
				return false;
			}

			/* put sample parameters */
			c->bit_rate = 25 * width * height/*400000*/;
			/* resolution must be a multiple of two */
			c->width = width;
			c->height = height;
			/* frames per second */
			//c->time_base = (AVRational) { 1, 25 };
			//c->framerate = (AVRational) { 25, 1 };
			c->time_base.den = 1;
			c->time_base.num = 25;
			c->framerate.den = 25;
			c->framerate.num = 1;
			c->refs = 1;

			/* emit one intra frame every ten frames
			* check frame pict_type before passing frame
			* to encoder, if frame->pict_type is AV_PICTURE_TYPE_I
			* then gop_size is ignored and the output of encoder
			* will always be I frame irrespective to gop_size
			*/
			c->gop_size = 25;
			c->max_b_frames = 0;
			c->pix_fmt = AV_PIX_FMT_YUV420P;

			c->codec_id = AV_CODEC_ID_H264;
			c->codec_type = AVMEDIA_TYPE_VIDEO;
			c->pix_fmt = AV_PIX_FMT_YUV420P;

			c->qmin = 10;
			c->qmax = 51;

			av_opt_set(c->priv_data, "tune", "zerolatency", 0);

			//film：  电影、真人类型；
			//	animation：  动画；
			//	grain：      需要保留大量的grain时用；
			//	stillimage：  静态图像编码时使用；
			//	psnr：      为提高psnr做了优化的参数；
			//	ssim：      为提高ssim做了优化的参数；
			//	fastdecode： 可以快速解码的参数；
			//	zerolatency：零延迟，用在需要非常低的延迟的情况下，比如电视电话会议的编码

			if (codec->id == AV_CODEC_ID_H264)
				av_opt_set(c->priv_data, "preset", "ultrafast", 0);  //ultrafast、superfast、veryfast、faster、fast、medium、slow、slower、veryslow、placebo

			/* open it */
			int ret = avcodec_open2(c, codec, NULL);
			if (ret < 0)
			{
				return false;
			}

			frame = av_frame_alloc();
			if (!frame)
			{
				fprintf(stderr, "Could not allocate video frame\n");
				return false;
			}
			frame->format = c->pix_fmt;
			frame->width = c->width;
			frame->height = c->height;

			ret = av_frame_get_buffer(frame, 1);
			if (ret < 0)
			{
				fprintf(stderr, "Could not allocate the video frame data\n");
				return false;
			}

			is_inited = true;
			return true;
		}
		void Uninit()
		{
			if (is_inited)
			{
				avcodec_free_context(&c);
				av_frame_free(&frame);
				av_packet_free(&pkt);
			}
		}

		bool is_inited = false;
		int index = 0;

		AVCodec* codec = NULL;
		AVCodecContext* c = NULL;
		AVFrame* frame;
		AVPacket* pkt;
		int width = 0;
		int height = 0;
	};

	static H264EncodeInfoStru* ptr_encode_info = NULL;

	static int C_ConvertYUVToH264(int channel, DataStruct* ptr_data, BufferNode* ptr_bs)
	{
		if (ptr_encode_info == NULL)
		{
			ptr_encode_info = new H264EncodeInfoStru;
		}

		if (ptr_encode_info->width != ptr_data->width_ || ptr_encode_info->height != ptr_data->height_)
		{
			ptr_encode_info->width = ptr_data->width_;
			ptr_encode_info->height = ptr_data->height_;
			ptr_encode_info->Uninit();
		}

		if (!ptr_encode_info->Init())
		{
			return -1;
		}

		fflush(stdout);

		int ret = av_frame_make_writable(ptr_encode_info->frame);
		if (ret < 0)
			return -1;

		ptr_encode_info->frame->data[0] = (uint8_t*)(ptr_data->buffer_);                   // Y
		ptr_encode_info->frame->data[1] = (uint8_t*)(ptr_data->buffer_ + ptr_encode_info->width * ptr_encode_info->height);          // U 
		ptr_encode_info->frame->data[2] = (uint8_t*)(ptr_data->buffer_ + ptr_encode_info->width * ptr_encode_info->height * 5 / 4);  // V

		ptr_encode_info->frame->pts = ptr_encode_info->index++;

		BufferNode* last = ptr_bs;

		ret = avcodec_send_frame(ptr_encode_info->c, ptr_encode_info->frame);
		if (ret < 0)
		{
			fprintf(stderr, "Error sending a frame for encoding\n");
			char* error_buf = new char[200];
			av_strerror(ret, error_buf, 200);
			fprintf(stderr, error_buf);
			delete[] error_buf;
			return -1;
		}

		while (ret >= 0)
		{
			ret = avcodec_receive_packet(ptr_encode_info->c, ptr_encode_info->pkt);

			if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
			{
				return 0;
			}
			else if (ret < 0)
			{
				return -1;
			}

			if (last->ptr_next == NULL)
			{
				last->ptr_next = new BufferNode;
			}
			last->ptr_next->length = (int)(ptr_encode_info->pkt->size);
			last->ptr_next->buffer = new char[last->ptr_next->length];

			memcpy(last->ptr_next->buffer, ptr_encode_info->pkt->data, last->ptr_next->length);

			last = last->ptr_next;

			av_packet_unref(ptr_encode_info->pkt);
		}
		
		return 0;
	}

	/******************encode rgb*********************************/

	struct H264EncodeRGBInfoStru
	{
		bool Init()
		{
			if (is_inited)
			{
				return true;
			}

			av_register_all();
			avformat_network_init();

			codec = avcodec_find_encoder(AV_CODEC_ID_H264);

			if (!codec)
			{
				return false;
			}

			c = avcodec_alloc_context3(codec);
			if (!c)
			{
				return false;
			}

			pkt = av_packet_alloc();
			if (!pkt)
			{
				return false;
			}

			int fps = 25;

			c->width = width;
			c->height = height;
			c->time_base.den = 1;
			c->time_base.num = fps;
			c->framerate.den = fps;
			c->framerate.num = 1;
			c->refs = 1;
			c->gop_size = fps;     // I帧间隔  如果设的太大，新连接上来得等I帧才开始解码
			c->max_b_frames = 0;
			c->has_b_frames = 0;
			c->pix_fmt = AV_PIX_FMT_YUV420P;
			c->codec_id = AV_CODEC_ID_H264;
			c->codec_type = AVMEDIA_TYPE_VIDEO;
			c->pix_fmt = AV_PIX_FMT_YUV420P;
			c->qmin = 10;
			c->qmax = 51;

			if (av_opt_set(c->priv_data, "tune", "zerolatency", 0) != 0)
			{
				Q_ASSERT(false);
			}
			if (av_opt_set(c->priv_data, "preset", "ultrafast", 0) != 0)
			{
				Q_ASSERT(false);
			}

			//av_opt_set_int(c->priv_data, "slice-max-size", 30000, 0);  //Replaces RTP Payload size

			//av_dict_set(&options, "buffer_size", "655360", 0);
			//if (av_opt_set_int(c->priv_data, "pkt_size", 8000, 0) != 0)
			//{
			//	Q_ASSERT(false);
			//}

			int ret = avcodec_open2(c, codec, NULL);
			if (ret < 0)
			{
				return false;
			}

			frame = av_frame_alloc();
			frame->format = c->pix_fmt;
			frame->width = c->width;
			frame->height = c->height;
			ret = av_frame_get_buffer(frame, 1);
			if (ret < 0)
			{
				fprintf(stderr, "Could not allocate video frame\n");
				return false;
			}

			//ptr_yuv_frame = av_frame_alloc();
			//ptr_rgb_frame = av_frame_alloc();
			ptr_yuv_frame = new AVFrame[1];
			ptr_rgb_frame = new AVFrame[1];

			//yuv_buffer = new uint8_t[width * height * 3 / 2];
			yuv_buffer = new uint8_t[GetBufferSize().width() * GetBufferSize().height() * 3 / 2];

			is_inited = true;
			return true;
		}
		void Uninit()
		{
			if (is_inited)
			{
				avcodec_free_context(&c);
				av_frame_free(&frame);
				av_packet_free(&pkt);

				delete[] ptr_yuv_frame;
				ptr_yuv_frame = NULL;

				delete[] ptr_rgb_frame;
				ptr_rgb_frame = NULL;

				delete[] yuv_buffer;
				yuv_buffer = NULL;

				is_inited = false;
			}
		}

		bool is_inited = false;
		int index = 0;

		AVCodec* codec = NULL;
		AVCodecContext* c = NULL;
		AVFrame* frame = NULL;
		AVPacket* pkt = NULL;
		int width = 0;
		int height = 0;

		AVFrame* ptr_yuv_frame = NULL;
		AVFrame* ptr_rgb_frame = NULL;

		uint8_t* yuv_buffer = NULL;
	};

	//static H264EncodeRGBInfoStru* ptr_h264_encode_rgb = new H264EncodeRGBInfoStru;

	static H264EncodeRGBInfoStru* encoders = new H264EncodeRGBInfoStru[10];
	static H264EncodeRGBInfoStru* GetEncoder(int channel)
	{
		return &encoders[channel];
	}

	static int C_ConvertRGBToH264(int channel, DataStruct* ptr_rgb_data, BufferNode* ptr_h264_node)
	{
		H264EncodeRGBInfoStru* ptr_h264_encode_rgb = GetEncoder(channel);
		if (ptr_h264_encode_rgb == NULL)
		{
			ptr_h264_encode_rgb = new H264EncodeRGBInfoStru;
		}

		if (ptr_h264_encode_rgb->width != ptr_rgb_data->width_ || ptr_h264_encode_rgb->height != ptr_rgb_data->height_)
		{
			ptr_h264_encode_rgb->width = ptr_rgb_data->width_;
			ptr_h264_encode_rgb->height = ptr_rgb_data->height_;
			ptr_h264_encode_rgb->Uninit();
		}

		if (!ptr_h264_encode_rgb->Init())
		{
			return -1;
		}

		// rbg to yuv
		avpicture_fill((AVPicture *)ptr_h264_encode_rgb->ptr_rgb_frame, (uint8_t *)ptr_rgb_data->buffer_, AV_PIX_FMT_RGB32, ptr_rgb_data->width_, ptr_rgb_data->height_);
		avpicture_fill((AVPicture *)ptr_h264_encode_rgb->ptr_yuv_frame, (uint8_t *)ptr_h264_encode_rgb->yuv_buffer, AV_PIX_FMT_YUV420P, ptr_rgb_data->width_, ptr_rgb_data->height_);

		SwsContext *img_convert_ctx = sws_getContext(ptr_rgb_data->width_, ptr_rgb_data->height_, AV_PIX_FMT_RGB32, ptr_rgb_data->width_, ptr_rgb_data->height_, AV_PIX_FMT_YUV420P, SWS_POINT, NULL, NULL, NULL);


		int temp = sws_scale(img_convert_ctx,
			(uint8_t const * const *)ptr_h264_encode_rgb->ptr_rgb_frame->data,
			ptr_h264_encode_rgb->ptr_rgb_frame->linesize,
			0,
			ptr_rgb_data->height_,
			ptr_h264_encode_rgb->ptr_yuv_frame->data,
			ptr_h264_encode_rgb->ptr_yuv_frame->linesize);

		sws_freeContext(img_convert_ctx);

		// yuv to h264
		fflush(stdout);

		int ret = av_frame_make_writable(ptr_h264_encode_rgb->frame);
		if (ret < 0)
			return -1;

		ptr_h264_encode_rgb->frame->data[0] = (uint8_t*)(ptr_h264_encode_rgb->yuv_buffer);                   // Y
		ptr_h264_encode_rgb->frame->data[1] = (uint8_t*)(ptr_h264_encode_rgb->yuv_buffer + ptr_h264_encode_rgb->width * ptr_h264_encode_rgb->height);          // U 
		ptr_h264_encode_rgb->frame->data[2] = (uint8_t*)(ptr_h264_encode_rgb->yuv_buffer + ptr_h264_encode_rgb->width * ptr_h264_encode_rgb->height * 5 / 4);  // V

		ptr_h264_encode_rgb->frame->pts = ptr_h264_encode_rgb->index++;

		//static int i = 0;
		//++i;
		//if (i % 20 == 0)
		//{
		//	ptr_h264_encode_rgb->frame->pict_type = AV_PICTURE_TYPE_I; //强制I帧    AV_PICTURE_TYPE_NONE默认
		//}
		//else
		//{
		//	ptr_h264_encode_rgb->frame->pict_type = AV_PICTURE_TYPE_NONE;
		//}
		
		ret = avcodec_send_frame(ptr_h264_encode_rgb->c, ptr_h264_encode_rgb->frame);
		if (ret < 0)
		{
			fprintf(stderr, "Error sending a frame for encoding\n");
			return -1;
		}

		bool packet_got = false;
		while (ret >= 0)
		{
			ret = avcodec_receive_packet(ptr_h264_encode_rgb->c, ptr_h264_encode_rgb->pkt);

			if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
			{
				return 0;
			}
			else if (ret < 0)
			{
				return -1;
			}

			if (packet_got)
			{
				// 一帧来个两个包？？？
				Q_ASSERT(false);
			}

			ptr_h264_node->length = (int)(ptr_h264_encode_rgb->pkt->size);
			memcpy(ptr_h264_node->buffer, ptr_h264_encode_rgb->pkt->data, ptr_h264_node->length);

			packet_got = true;

			av_packet_unref(ptr_h264_encode_rgb->pkt);
		}
	}

	/******************decode*****************************/

	struct H264DecodeInfoStru
	{
		bool Init()
		{
			if (is_inited)
			{
				return true;
			}

			//av_log_set_level(AV_LOG_QUIET);

			av_register_all();
			avformat_network_init();

			m_pCodec = avcodec_find_decoder(AV_CODEC_ID_H264);
			m_pCodecCtx = avcodec_alloc_context3(m_pCodec);
			avcodec_open2(m_pCodecCtx, m_pCodec, 0);
			m_pFrame = av_frame_alloc();

			is_inited = true;
			return true;
		}
		void Uninit()
		{
			if (is_inited)
			{
				avcodec_free_context(&m_pCodecCtx);
				av_frame_free(&m_pFrame);
			}
		}

		bool is_inited = false;
		int index = 0;

		AVCodecContext  *m_pCodecCtx;
		AVCodec         *m_pCodec;
		AVFrame         *m_pFrame;
	};

	static H264DecodeInfoStru* ptr_decode_info = NULL;

	static int C_ConvertH264ToYUV(int channel, BufferNode* ptr_bs, DataStruct* ptr_data)
	{
		if (ptr_decode_info == NULL)
		{
			ptr_decode_info = new H264DecodeInfoStru;
		}

		if (!ptr_decode_info->Init())
		{
			return -1;
		}

		AVPacket        packet;
		av_init_packet(&packet);

		packet.data = (uint8_t *)ptr_bs->buffer;
		packet.size = ptr_bs->length;

		avcodec_send_packet(ptr_decode_info->m_pCodecCtx, &packet);
		int ret = avcodec_receive_frame(ptr_decode_info->m_pCodecCtx, ptr_decode_info->m_pFrame);

		if (ret == 0)
		{
			int w = ptr_decode_info->m_pFrame->width;//ptr_decode_info->m_pFrame->width;
			int h = ptr_decode_info->m_pFrame->height;
			ptr_data->width_ = w;
			ptr_data->height_ = h;
			ptr_data->buffer_length_ = w * h * 3 / 2;
			ptr_data->buffer_ = new char[ptr_data->buffer_length_];

			// 由于linesize与宽度可能不一致  （宽900时linesize1024 类似内存对齐）  读取数据时按linesize读取   
			int a = 0, i;
			for (i = 0; i < h; i++)
			{
				memcpy(ptr_data->buffer_ + a, ptr_decode_info->m_pFrame->data[0] + i * ptr_decode_info->m_pFrame->linesize[0], w);
				a += w;
			}
			for (i = 0; i < h / 2; i++)
			{
				memcpy(ptr_data->buffer_ + a, ptr_decode_info->m_pFrame->data[1] + i * ptr_decode_info->m_pFrame->linesize[1], w / 2);
				a += w / 2;
			}
			for (i = 0; i < h / 2; i++)
			{
				memcpy(ptr_data->buffer_ + a, ptr_decode_info->m_pFrame->data[2] + i * ptr_decode_info->m_pFrame->linesize[2], w / 2);
				a += w / 2;
			}

			//memcpy(ptr_data->buffer_, ptr_decode_info->m_pFrame->data[0], w * h);
			//memcpy(ptr_data->buffer_ + w * h, ptr_decode_info->m_pFrame->data[1], w * h / 4);
			//memcpy(ptr_data->buffer_ + w * h * 5 / 4, ptr_decode_info->m_pFrame->data[2], w * h / 4);
		}

		return 0;
	}

	/************************* h264 to rgb **********************************/

	struct H264DecodeRGBInfoStru
	{
		bool Init()
		{
			if (is_inited)
			{
				return true;
			}

			//av_log_set_level(AV_LOG_QUIET);

			av_register_all();
			avformat_network_init();

			m_pCodec = avcodec_find_decoder(AV_CODEC_ID_H264);
			m_pCodecCtx = avcodec_alloc_context3(m_pCodec);
			avcodec_open2(m_pCodecCtx, m_pCodec, 0);
			m_pFrame = av_frame_alloc();

			ptr_yuv_frame = new AVFrame[1];
			ptr_rgb_frame = new AVFrame[1];

			yuv_buffer = new uint8_t[GetBufferSize().width() * GetBufferSize().height() * 3 / 2];

			is_inited = true;
			return is_inited;
		}
		void Uninit()
		{
			if (is_inited)
			{
				avcodec_free_context(&m_pCodecCtx);
				av_frame_free(&m_pFrame);

				delete[] ptr_yuv_frame;
				delete[] ptr_rgb_frame;

				delete[] yuv_buffer;
			}
		}

		bool is_inited = false;
		int index = 0;

		AVCodecContext  *m_pCodecCtx;
		AVCodec         *m_pCodec;
		AVFrame         *m_pFrame;

		AVFrame* ptr_yuv_frame = NULL;
		AVFrame* ptr_rgb_frame = NULL;

		uint8_t* yuv_buffer = NULL;
	};

	static H264DecodeRGBInfoStru* ptr_h264_decode_rgb = NULL;

	static int C_ConvertH264ToRGB(int channel, BufferNode* ptr_bs, DataStruct* ptr_rgb_data)
	{
		if (ptr_h264_decode_rgb == NULL)
		{
			ptr_h264_decode_rgb = new H264DecodeRGBInfoStru;
		}

		if (!ptr_h264_decode_rgb->Init())
		{
			return -1;
		}

		AVPacket        packet;
		av_init_packet(&packet);

		packet.data = (uint8_t *)ptr_bs->buffer;
		packet.size = ptr_bs->length;

		avcodec_send_packet(ptr_h264_decode_rgb->m_pCodecCtx, &packet);
		int ret = avcodec_receive_frame(ptr_h264_decode_rgb->m_pCodecCtx, ptr_h264_decode_rgb->m_pFrame);

		if (ret != 0)
		{
			return -1;
		}

		int width = ptr_h264_decode_rgb->m_pFrame->width;
		int height = ptr_h264_decode_rgb->m_pFrame->height;

		//	// todo: 当外部尺寸固定为16倍数时，改为直接拷贝整段内存
		//	// 由于linesize与宽度可能不一致  （宽900时linesize1024 类似内存对齐）  读取数据时按linesize读取   
		int a = 0, i;
		for (i = 0; i < height; i++)
		{
			memcpy(ptr_h264_decode_rgb->yuv_buffer + a, ptr_h264_decode_rgb->m_pFrame->data[0] + i * ptr_h264_decode_rgb->m_pFrame->linesize[0], width);
			a += width;
		}
		for (i = 0; i < height / 2; i++)
		{
			memcpy(ptr_h264_decode_rgb->yuv_buffer + a, ptr_h264_decode_rgb->m_pFrame->data[1] + i * ptr_h264_decode_rgb->m_pFrame->linesize[1], width / 2);
			a += width / 2;
		}
		for (i = 0; i < height / 2; i++)
		{
			memcpy(ptr_h264_decode_rgb->yuv_buffer + a, ptr_h264_decode_rgb->m_pFrame->data[2] + i * ptr_h264_decode_rgb->m_pFrame->linesize[2], width / 2);
			a += width / 2;
		}

		ptr_rgb_data->width_ = width;
		ptr_rgb_data->height_ = height;
		ptr_rgb_data->buffer_length_ = ((width * 32 + 31) / 32) * 4 * height;

		avpicture_fill((AVPicture *)ptr_h264_decode_rgb->ptr_rgb_frame, (uint8_t *)ptr_rgb_data->buffer_, AV_PIX_FMT_RGB32, width, height);

		avpicture_fill((AVPicture *)ptr_h264_decode_rgb->ptr_yuv_frame, (uint8_t *)ptr_h264_decode_rgb->yuv_buffer, AV_PIX_FMT_YUV420P, width, height);

		SwsContext *img_convert_ctx = sws_getContext(width, height, AV_PIX_FMT_YUV420P, width, height, AV_PIX_FMT_RGB32, SWS_POINT, NULL, NULL, NULL);

		int temp = sws_scale(img_convert_ctx,
			(uint8_t const * const *)ptr_h264_decode_rgb->ptr_yuv_frame->data,
			ptr_h264_decode_rgb->ptr_yuv_frame->linesize, 0, height, ptr_h264_decode_rgb->ptr_rgb_frame->data,
			ptr_h264_decode_rgb->ptr_rgb_frame->linesize);

		sws_freeContext(img_convert_ctx);

		return 0;
	}

#ifdef __cplusplus 
}
#endif

int ConvertYUVToH264(int channel, DataStruct* ptr_data, BufferNode* ptr_bs)
{
	return C_ConvertYUVToH264(channel, ptr_data, ptr_bs);
}

int ConvertH264ToYUV(int channel, BufferNode* ptr_bs, DataStruct* ptr_data)
{
	return C_ConvertH264ToYUV(channel, ptr_bs, ptr_data);
}

int ConvertRGBToH264(int channel, DataStruct* ptr_data, BufferNode* ptr_bs)
{
	return C_ConvertRGBToH264(channel, ptr_data, ptr_bs);
}

int ConvertH264ToRGB(int channel, BufferNode* ptr_h264, DataStruct* ptr_rgb_data)
{
	return C_ConvertH264ToRGB(channel, ptr_h264, ptr_rgb_data);
}
